---
layout: post
title:  Implementing B+ Trees on Disk, Part 1 (Draft)
date:   2025-01-13 10:00
categories: database b+ tree
---

In this series we will be implementing a disk based B+ tree using OCaml. In this part I will provide a motivation for the challenge of implementing a disk based B+ tree, and then dig into the underlying storage manager that the higher level B+ tree algorithm will rely upon. In part 2 we will cover node layout on disk and serialization/deserialization functionality. Part 3 will cover insertion into the tree, and finally part 4 will cover deletion and some auxiliary functions derived from the implementation at that point. 

There are many resources on the basics of B+ trees and the associated algorithms for inserting and deleting from the tree, but they miss one crucial aspect: actually storing and maintaining the B+ tree on disk. It's easy enough to implement an in memory data structure and have it working while our program is running -- but how do we persist the information on disk when our program stops running or the computer shuts off? I will assume some familiarity with what a B+ tree is and why we need one in the first place. We won't get to the actual B+ tree insertion/deletion algorithms until later, when we have all the low level disk access and layout methods implemented. 

This is part of my OCaml_DB project, although the tutorial should be agnostic from any particular database, and hopefully you can follow along and hook it up to your own database. Also, even though I will be using OCaml, a lot of the code is imperative in nature and I think has a similar feeling to programming in a language like Rust or Go, with the added benefit of an exceptional type system and ease of reading compared to a language like Rust. Furthermore, I didn't consult any resources for how B+ trees are implemented in practice; this was my own attempt of designing an on disk B+ tree, so use it as inspiration to design your own if anything I do is particularly egregious, and also I would be very happy to hear about how you would design things differently. Future blog posts may include 1) comparing our implementation to existing B+ trees, and seeing where we can make some improvement with that knowledge and 2) showing how I hook up our B+ tree to OCaml_DB, and intertwining it with our transaction and buffer pool managers.

First off, here is a straw man design for making a disk based B+ tree to showcase the challenge we are really trying to solve. The "stupid" design would be as follows: when we are running a B+ tree operation, get the entire tree from disk at once and deserialize it it into an in memory representation of the tree. Then you would be able to write your code simply following any suitable pseudocode, without worrying about disk operations. At the end, you serialize and write it back to disk and you are done. There are a few clear problems with this approach. It requires reading the entire tree from disk, which is proporitonal to a linear scan on the original table in the first place. This defeats the entire purpose of having a B+ tree in the first place. Even if you can do it just one time and keep it cached in memory, the table you are indexing can be massive, either exceeding available RAM or taking up too much space. 

So we have to ensure we are keeping both look up time and associated memory footprint to a minimum; the two are related since the fewer disk accesses we have to make, the quicker the algorithm will run as well as having a lower associated memory footprint. This implies we want to keep the disk access localized to particular nodes during traversal in the algorithm. Suppose we have a degenerate case of a B+ tree that is just a binary search tree; it has one key and two pointers. The pseudocode for traversing the internal nodes of the B+ tree to get to the leaf level could look something like this: 

```
fun find_key key node_pointer = 
    node = read_from_disk node_pointer 
    match node.type with 
    | Internal -> 
        if key <= node.key:
        then 
            find_key key node.left_pointer 
        else
            find_key key node.right_pointer 
    | Leaf -> ...
```

And the traversal can be kicked off with a pointer to the root node: 

```
find_key key root_pointer
```

Instead of passing around an explicit node, we will be passing along "pointers" to where the nodes can be found on disk. For a traversal, we deserialize the node from disk and then use the in memory representation within our function logic. Instead of recursively calling the function on a node, we pass a child pointer to where the next node is located on disk. 

If we have to make some modification to a node, we just make sure we write back to disk to the location specified by the pointer. For example, if we have a function to insert a value in a leaf node (assuming there is space in the node):

```
fun insert_in_leaf key record_pointer leaf_pointer = 
    node = read_from_disk leaf_pointer
    // Insert (key, record_pointer) in appropriate location. 
    ...
    write_to_disk node leaf_pointer
```

This leads us to our first design decision: Our B+ tree will be stored in a file on disk. Each node of the tree will be a block of the file. The block size can be arbitrary; for simplicity we will assume it aligns with the unit of block access provided by the hardware. For something like a binary search tree, this would be extremely inefficient, since we would only have one key and two child pointers taking up an entire block. So we want to make sure we are padding as many key and pointer values into a block as possible; this will be discussed in part 2. This also works perfectly with the intended structure of a B+ tree; since we want to minimize the number of disk accesses, we want to increase the fanout of the tree as much as possible. 









